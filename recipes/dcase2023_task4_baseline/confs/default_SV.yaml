training:
  #batch size: [synth, weak, unlabel]
  batch_size: [6, 6, 6]
  batch_size_val: 6
  const_max: 2 # max weight used for self supervised loss
  n_epochs_warmup: 50 # num epochs used for exponential warmup
  num_workers: 24 # change according to your cpu
  n_epochs: 500 # max num epochs
  early_stop_patience: 200 # Same as number of epochs by default, so no early stopping used
  accumulate_batches: 1
  gradient_clip: 0. # 0 no gradient clipping
  median_window: 7 # length of median filter used to smooth prediction in inference (nb of output frames)
  val_thresholds: [0.5] # thresholds used to compute f1 intersection in validation.
  n_test_thresholds: 50 # number of thresholds used to compute psds in test
  ema_factor: 0.999 # ema factor for mean teacher
  self_sup_loss: mse # bce or mse for self supervised mean teacher loss
  backend: dp # pytorch lightning backend, ddp, dp or None  # No longer Updated. Previously "dp"
  validation_interval: 1 # perform validation every X epoch, 1 default
  weak_split: 0.9
  seed: 42
  deterministic: False
  precision: 32
  mixup: soft # Soft mixup gives the ratio of the mix to the labels, hard mixup gives a 1 to every label present.
  obj_metric_synth_type: intersection
  precision: 32
  enable_progress_bar: True
scaler:
  statistic: instance # instance or dataset-wide statistic
  normtype: minmax # minmax or standard or mean normalization
  dims: [1, 2] # dimensions over which normalization is applied
  savepath: ./scaler.ckpt # path to scaler checkpoint
data: # change with your paths if different.
  # NOTE: if you have data in 44kHz only then synth_folder will be the path where
  # resampled data will be placed.
  synth_folder: "/srv/shared_data/multiple_single_events/24_bits/synth_train_16k/"
  synth_folder_44k: "/srv/shared_data/multiple_single_events/24_bits/synth_train/"
  synth_tsv: "/srv/shared_data/multiple_single_events/metadata/synth_train.tsv"
  strong_folder: "/srv/shared_data/multiple_single_events/24_bits/strong_16k/"
  strong_folder_44k: "/srv/shared_data/multiple_single_events/24_bits/strong/"
  strong_tsv: "/srv/shared_data/multiple_single_events/metadata/strong.tsv"
  weak_folder: "/srv/shared_data/multiple_single_events/24_bits/weak_16k/"
  weak_folder_44k: "/srv/shared_data/multiple_single_events/24_bits/weak/"
  weak_tsv: "/srv/shared_data/multiple_single_events/metadata/weak.tsv"
  unlabeled_folder: "/srv/shared_data/multiple_single_events/24_bits/unlabeled_16k/"
  unlabeled_folder_44k: "/srv/shared_data/multiple_single_events/24_bits/unlabeled/"
  unlabeled_tsv:  "/srv/shared_data/multiple_single_events/metadata/unlabeled.tsv"
  synth_val_folder: "/srv/shared_data/multiple_single_events/24_bits/synth_val_16k/"
  synth_val_folder_44k: "/srv/shared_data/multiple_single_events/24_bits/synth_val/"
  synth_val_tsv: "/srv/shared_data/multiple_single_events/metadata/synth_val.tsv"
  synth_val_dur: "/srv/shared_data/multiple_single_events/metadata/synth_val_duration.tsv"
  test_folder: "/srv/shared_data/multiple_single_events/24_bits/test_16k/"
  test_folder_44k: "/srv/shared_data/multiple_single_events/24_bits/test/"
  test_tsv: "/srv/shared_data/multiple_single_events/metadata/test.tsv"
  test_dur: "/srv/shared_data/multiple_single_events/metadata/test_duration.tsv"
  eval_folder: "/srv/shared_data/multiple_single_events/24_bits/eval/"
  eval_folder_44k: "/srv/shared_data/multiple_single_events/24_bits/eval/"
  predict_folder: "/predict_16k"
  predict_folder_44k: "../../data/small_dataset/" ####
  predict_from_checkpoint: "../../recipes/dcase2023_task4_baseline/pre_trained_checkpoints/ckpt/legacy_epoch=176-step=20886.ckpt"
  audio_max_len: 40
  fs: 16000
  net_subsample: 4
opt:
  lr: 0.001
feats:
  n_mels: 128
  n_filters: 4096
  hop_length: 256
  n_window: 2048
  sample_rate: 16000
  f_min: 0
  f_max: 8000
net:
  dropout: 0.5
  rnn_layers: 2
  n_in_channel: 1
  nclass: 2
  attention: True
  n_RNN_cell: 128
  activation: glu
  rnn_type: BGRU
  kernel_size: [3, 3, 3, 3, 3, 3, 3]
  padding: [1, 1, 1, 1, 1, 1, 1]
  stride: [1, 1, 1, 1, 1, 1, 1]
  nb_filters: [ 16, 32, 64, 128, 128, 128, 128 ]
  pooling: [ [ 2, 2 ], [ 2, 2 ], [ 1, 2 ], [ 1, 2 ], [ 1, 2 ], [ 1, 2 ], [ 1, 2 ] ]
  dropout_recurrent: 0
  use_embeddings: False